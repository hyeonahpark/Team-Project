# pushup.py
import cv2
import joblib
import math
import numpy as np
from PIL import ImageFont, Image, ImageDraw
import mediapipe as mp
import time
from ultralytics import YOLO

label = ['ì •ìì„¸', 'ì˜¤ìì„¸']
model = YOLO('yolov5/yolo11n.pt')
pushup_model = joblib.load('C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/_data/ìš´ë™ë³„ ëª¨ë¸/crunch.pkl')
font_path = "C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/_data/ê°•ì›êµìœ¡íŠ¼íŠ¼.ttf"
font = ImageFont.truetype(font_path, 20)

mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose

def crunch_info(st):
    st.markdown("<h1 style='text-align: center;'>ğŸ‹ï¸â€â™‚ï¸ AI í™ˆíŠ¸ë ˆì´ë„ˆ</h1>", unsafe_allow_html=True)
    st.markdown("<h2 style='text-align: center;'>í¬ëŸ°ì¹˜</h1>", unsafe_allow_html=True)

    with st.container():
        st.markdown("""
                <div style="
                    background-color: #fff; 
                    padding: 30px; 
                    border-radius: 15px; 
                    border: 1px solid #ddd; 
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); 
                    max-width: 600px; 
                    margin: auto;
                    font-family: 'Roboto', Arial, sans-serif;
                ">
                    <div>
                        <h2 style="font-size: 20px; color: #333; margin: 0; text-align: center;">í¬ëŸ°ì¹˜</h3>
                        <h3 style="font-size: 18px; color: #333; margin: 0;">1. ì¹´ë©”ë¼ ì„¤ì • ì•ˆë‚´</h3>
                        <ul style="font-size: 14px; color: #555; line-height: 1.8; padding-left: 20px; margin-top: 10px;">
                            <li>íœ´ëŒ€í°ì„ ë°”ë‹¥ì— ì„¸ì›Œë‘ì‹œê³ , <b>ì¢Œì¸¡</b> ë˜ëŠ” <b>ìš°ì¸¡ ì „ì‹ </b>ì´ í™”ë©´ì— ì˜ ë‚˜ì˜¤ë„ë¡ ì¹´ë©”ë¼ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.</li>
                            <li>ì£¼ë³€ í™˜ê²½ì´ ë°ê³ , ì´¬ì˜ì— ë°©í•´ë˜ì§€ ì•Šë„ë¡ ì •ë¦¬í•´ì£¼ì„¸ìš”.</li>
                        </ul>
                    </div>
                    <div style="
                        border-top: 1px solid #eee; 
                        padding-top: 20px; 
                        margin-top: 20px;
                    ">
                        <h3 style="font-size: 18px; color: #333; margin: 0;">2. ìš´ë™ ì‹œì‘</h3>
                        <ul style="font-size: 14px; color: #555; line-height: 1.8; padding-left: 20px; margin-top: 10px;">
                            <li>ì¤€ë¹„ê°€ ì™„ë£Œë˜ì…¨ë‹¤ë©´, 'ë‹¤ìŒ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!</li>
                            <li>ìš´ë™ì´ ë°”ë¡œ ì‹œì‘ë©ë‹ˆë‹¤!</li>
                        </ul>
                    </div>
                </div>
                """, unsafe_allow_html=True)
        st.image("C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/_data/í¬ëŸ°ì¹˜.png", use_container_width=True)
    
        if st.button("ë‹¤ìŒ"):
            st.session_state.current_exercise_state = "camera"
            st.rerun()

def calculate_distance(point1, point2):
    return math.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2 + (point1.z - point2.z)**2)


def calculate_angle(a, b, c):
    if hasattr(a, 'x'):
        a = np.array([a.x, a.y, a.z])
        b = np.array([b.x, b.y, b.z])
        c = np.array([c.x, c.y, c.z])
    else:
        a = np.array(a)
        b = np.array(b)
        c = np.array(c)
    ba = a - b
    bc = c - b
    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
    angle = np.degrees(np.arccos(cosine_angle))
    return angle


def flip_landmarks(landmarks):
    flipped = [None] * len(landmarks)
    swap_indices = {0: 0, 1: 4, 2: 5, 3: 6, 4: 1, 5: 2, 6: 3, 7: 8, 8: 7, 9: 10, 10: 9, 11: 12, 12: 11, 13: 14,
                   14: 13, 15: 16, 16: 15, 17: 18, 18: 17, 19: 20, 20: 19, 21: 22, 22: 21, 23: 24, 24: 23, 25: 26,
                   26: 25, 27: 28, 28: 27, 29: 30, 30: 29, 31: 32, 32: 31}
    for idx, lm in enumerate(landmarks):
        # ì¢Œìš° ëŒ€ì¹­ ìœ„ì¹˜ ê²°ì •
        new_idx = swap_indices.get(idx, idx)  # ì¢Œìš°ê°€ ë°”ë€ŒëŠ” ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
        flipped[new_idx] = type(lm)(
            x=1.0 - lm.x,  # X ì¢Œí‘œ ë°˜ì „
            y=lm.y,  # Y, Z ì¢Œí‘œëŠ” ê·¸ëŒ€ë¡œ
            z=lm.z,
            visibility=lm.visibility
        )
    return flipped

def run_crunch_session(st, YOLO, info):
    # ì´ˆê¸° ë³€ìˆ˜ ì„¤ì •
    total_history = []  # ì „ì²´ í”„ë ˆì„ì˜ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
    correct_threshold = 0.5  # ì •ìì„¸ ë¹„ìœ¨ ê¸°ì¤€ (70%)
    frame_skip = 4
    frame_count = 0
    crunch_state = "ë‚´ë ¤ê°"  # ì´ˆê¸° ìƒíƒœ
    crunch_count = 0  # ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
    wrong_crunch_count = 0
    
    # ì„¸íŠ¸ ë° íšŸìˆ˜ ì„¤ì •
    target_reps = info["íšŸìˆ˜"]  # ëª©í‘œ íšŸìˆ˜
    target_sets = info["ì„¸íŠ¸"]  # ëª©í‘œ ì„¸íŠ¸
    completed_sets = 0  # ì™„ë£Œëœ ì„¸íŠ¸ ìˆ˜

    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    results_dict = {
        "ì •ìì„¸ íšŸìˆ˜": 0,
        "ì˜¤ìì„¸ íšŸìˆ˜": 0,
        "ë¬´ë¦ì´ ë°œëì„ ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.": 0,
        "ëª¸ì˜ ê· í˜•ì„ ìœ ì§€í•˜ì„¸ìš”. ìƒì²´ê°€ ë„ˆë¬´ ê¸°ìš¸ì–´ì¡ŒìŠµë‹ˆë‹¤.": 0,
        "ì—‰ë©ì´ì™€ í—ˆë¦¬ë¥¼ ì¼ì§ì„ ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”.": 0
    }

    # MediaPipe Pose ì´ˆê¸°í™”
    mp_drawing = mp.solutions.drawing_utils
    mp_pose = mp.solutions.pose

    # ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ ì´ˆê¸°í™”
    st.markdown("<h1 style='text-align: center;'>í¬ëŸ°ì¹˜</h1>", unsafe_allow_html=True)

    # ìŠ¤íŠ¸ë¦¬ë° ë¹„ë””ì˜¤ í”¼ë“œ ì„¤ì •
    video_url = "C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/ì˜ìƒ/í¬ëŸ°ì¹˜/ì‚¬ì˜1.mp4"
    ip_webcam_url = "http://192.168.0.98:8080/video"    

    # ì±„íŒ… ë©”ì‹œì§€ ì°½
    frame_placeholder = st.empty()
    chat_placeholder = st.empty()
    count_placeholder = st.empty()
    set_placeholder = st.empty()  # ì„¸íŠ¸ í‘œì‹œìš©

    # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    cap = cv2.VideoCapture(video_url)  # ë™ì˜ìƒ ì…ë ¥
    # cap = cv2.VideoCapture(0)       # ì›¹ìº 
    # cap = cv2.VideoCapture(ip_webcam_url) # í° ì¹´ë©”ë¼
    # cap.set(cv2.CAP_PROP_FPS, 15)

    if "feedback_display_start_time" not in st.session_state:
        st.session_state.feedback_display_start_time = None 

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        if frame_count % frame_skip != 0:  # í”„ë ˆì„ ê±´ë„ˆë›°ê¸°
            continue
        
        # frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
        
        # YOLO ëª¨ë¸ë¡œ ì‚¬ëŒ ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
        results = model(frame)
        best_box = None
        best_confidence = 0.0

        for result in results:
            for box in result.boxes:
                class_id = box.cls[0]
                confidence = box.conf[0]
                if int(class_id) == 0 and confidence > best_confidence:
                    best_box = box
                    best_confidence = confidence

        if best_box is not None:
            x1, y1, x2, y2 = map(int, best_box.xyxy[0])
            person_roi = frame[y1:y2, x1:x2]

            with mp_pose.Pose(static_image_mode=False, model_complexity=1) as pose:
                results_pose = pose.process(cv2.cvtColor(person_roi, cv2.COLOR_BGR2RGB))
                landmarks_data = []

                if results_pose.pose_landmarks:
                    try:
                        landmarks = results_pose.pose_landmarks.landmark
                        
                        # ì–¼êµ´ ë°©í–¥ í™•ì¸ (ì™¼ìª½ ë˜ëŠ” ì˜¤ë¥¸ìª½)
                        # nose_x = landmarks[0].x  # ì½”ì˜ X ì¢Œí‘œ
                        # shoulder_center_x = (landmarks[11].x + landmarks[12].x) / 2  # ì–´ê¹¨ ì¤‘ì‹¬ì˜ X ì¢Œí‘œ
                        # is_left_facing = nose_x > shoulder_center_x
                        
                        # # ì™¼ìª½ì„ ë°”ë¼ë³´ëŠ” ê²½ìš° ëœë“œë§ˆí¬ ì¢Œìš° ëŒ€ì¹­ ë³€í™˜
                        # if is_left_facing:
                        #     landmarks = flip_landmarks(landmarks)  # ì¢Œìš° ëŒ€ì¹­ ë³€í™˜
                        
                        # ëœë“œë§ˆí¬ ë°ì´í„° ìƒì„±
                        landmarks_data = []
                        for landmark in landmarks:
                            landmarks_data.extend([landmark.x, landmark.y, landmark.z])

                        # í—ˆë¦¬ ì¢Œí‘œ ê³„ì‚°
                        waist_x = (landmarks[23].x + landmarks[24].x) / 2
                        waist_y = (landmarks[23].y + landmarks[24].y) / 2
                        waist_z = (landmarks[23].z + landmarks[24].z) / 2
                        landmarks_data.extend([waist_x, waist_y, waist_z])

                        # ê°ë„ ê³„ì‚°
                        left_knee_angle = calculate_angle(landmarks[23], landmarks[25], landmarks[27])
                        right_knee_angle = calculate_angle(landmarks[24], landmarks[26], landmarks[28])
                        left_hip_angle = calculate_angle(landmarks[11], landmarks[23], landmarks[25])
                        right_hip_angle = calculate_angle(landmarks[12], landmarks[24], landmarks[26])
                        landmarks_data.extend([
                            left_knee_angle, right_knee_angle,
                            left_hip_angle, right_hip_angle,
                        ])

                        # ìì„¸ ì˜ˆì¸¡
                        prediction = pushup_model.predict([landmarks_data])
                        prediction_text = label[int(prediction[0])]

                        total_history.append(prediction_text == "ì •ìì„¸")
                        correct_ratio = sum(total_history) / len(total_history)
                        
                        # ì–´ê¹¨, ì—‰ë©ì´, ë¬´ë¦ ì¢Œí‘œ ì¶”ì¶œ
                        shoulder = (landmarks[11].x, landmarks[11].y, landmarks[11].z)
                        hip = (landmarks[23].x, landmarks[23].y, landmarks[23].z)
                        knee = (landmarks[25].x, landmarks[25].y, landmarks[25].z)
                        
                        # í¬ëŸ°ì¹˜ ë™ì‘ íŒë³„
                        if crunch_state == "ì˜¬ë¼ê°":
                            angle = calculate_angle(shoulder, hip, knee)
                            print(f"í˜„ì¬ ê°ë„: {angle:.2f}")
                            if angle > 94 and correct_ratio >= correct_threshold:  # ê°ë„ê°€ 90ë„ ì´í•˜ë¡œ ë‚´ë ¤ê°”ì„ ë•Œ
                                print("ê°ë„ê°€ ì¶©ë¶„íˆ ë‚´ë ¤ê°”ìŠµë‹ˆë‹¤!")
                                crunch_state = "ë‚´ë ¤ê°"  # ìƒíƒœ ì „í™˜
                                print(crunch_state)
                                total_history=[]

                        elif crunch_state == "ë‚´ë ¤ê°":
                            angle = calculate_angle(shoulder, hip, knee)
                            print(f"í˜„ì¬ ê°ë„: {angle:.2f}")
                            if angle < 90 :
                                if correct_ratio >= correct_threshold:  # ê°ë„ê°€ ì¶©ë¶„íˆ ì˜¬ë¼ê°”ì„ ë•Œ
                                    print("ê°ë„ê°€ ì¶©ë¶„íˆ ì˜¬ë¼ê°”ìŠµë‹ˆë‹¤!")
                                    crunch_count += 1  # ì¹´ìš´íŠ¸ ì¦ê°€
                                    print(f"í¬ëŸ°ì¹˜ ë™ì‘ ì™„ë£Œ! í˜„ì¬ ì¹´ìš´íŠ¸: {crunch_count}")
                                    crunch_state = "ì˜¬ë¼ê°"  # ìƒíƒœ ì „í™˜
                                    print(crunch_state)
                                    
                                    if crunch_count == target_reps:
                                        completed_sets += 1
                                        crunch_count = 0
                                        
                                        if completed_sets == target_sets:
                                            st.success("ëª¨ë“  ì„¸íŠ¸ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!")
                                            cap.release()
                                            cv2.destroyAllWindows()
                                            results_dict["ì •ìì„¸ íšŸìˆ˜"] = completed_sets * target_reps
                                            return results_dict
                                else:
                                    wrong_crunch_count += 1
                                    crunch_state = "ì˜¬ë¼ê°"
                        
                        # "ì˜¤ìì„¸"ì¸ ê²½ìš° í”¼ë“œë°± ìƒì„± ë° ì¶œë ¥
                        if prediction_text == "ì˜¤ìì„¸":
                            feedback_messages = []

                            # ë¬´ë¦-ë°œë ì •ë ¬ í”¼ë“œë°±
                            knee_to_toe_distance = abs(landmarks[25].x - landmarks[27].x)  # ì™¼ìª½ ë¬´ë¦ê³¼ ë°œì˜ Xì¢Œí‘œ ì°¨ì´
                            if knee_to_toe_distance > 0.15:  # ë¬´ë¦ì´ ë°œëì„ ì§€ë‚˜ì³¤ì„ ë•Œ
                                results_dict["ë¬´ë¦ì´ ë°œëì„ ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”."] += 1
                                feedback_messages.append("ë¬´ë¦ì´ ë°œëì„ ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.")

                            # ëª¸ì˜ ê· í˜• í”¼ë“œë°±
                            body_tilt_angle = calculate_angle(landmarks[11], landmarks[23], landmarks[25])  # ìƒì²´ ê¸°ìš¸ê¸°
                            if body_tilt_angle < 75 or body_tilt_angle > 105:  # ëª¸ì´ ë„ˆë¬´ ê¸°ìš¸ì–´ì¡Œì„ ë•Œ
                                results_dict["ëª¸ì˜ ê· í˜•ì„ ìœ ì§€í•˜ì„¸ìš”. ìƒì²´ê°€ ë„ˆë¬´ ê¸°ìš¸ì–´ì¡ŒìŠµë‹ˆë‹¤."] += 1
                                feedback_messages.append("ëª¸ì˜ ê· í˜•ì„ ìœ ì§€í•˜ì„¸ìš”. ìƒì²´ê°€ ë„ˆë¬´ ê¸°ìš¸ì–´ì¡ŒìŠµë‹ˆë‹¤.")

                            # ì—‰ë©ì´ì™€ í—ˆë¦¬ ìœ„ì¹˜ í”¼ë“œë°±
                            hip_knee_alignment = calculate_angle(landmarks[23], landmarks[25], landmarks[27])  # ì—‰ë©ì´-ë¬´ë¦-ë°œëª© ê°ë„
                            if hip_knee_alignment < 90 or hip_knee_alignment > 120:  # ì—‰ë©ì´ê°€ ë„ˆë¬´ ë‚®ê±°ë‚˜ ë†’ì„ ë•Œ
                                results_dict["ì—‰ë©ì´ì™€ í—ˆë¦¬ë¥¼ ì¼ì§ì„ ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”."] += 1
                                feedback_messages.append("ì—‰ë©ì´ì™€ í—ˆë¦¬ë¥¼ ì¼ì§ì„ ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”.")
                                                    
                            # í”¼ë“œë°± ì¶œë ¥
                            if feedback_messages:
                                feedback_text = "<br>".join(feedback_messages)
                                chat_placeholder.markdown(feedback_text, unsafe_allow_html=True)
                                st.session_state.feedback_display_start_time = time.time()  # í”¼ë“œë°± í‘œì‹œ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                        else:
                            # "ì˜¤ìì„¸"ê°€ ì•„ë‹ ê²½ìš° í”¼ë“œë°± ë‚´ìš©ì„ 5ì´ˆ í›„ì— ì§€ì›ë‹ˆë‹¤.
                            if st.session_state.feedback_display_start_time and time.time() - st.session_state.feedback_display_start_time > 5:
                                chat_placeholder.markdown("", unsafe_allow_html=True)
                                st.session_state.feedback_display_start_time = None  # í‘œì‹œ ì‹œê°„ ì´ˆê¸°í™”
                        
                        #  # ì¶œë ¥ í…ìŠ¤íŠ¸ ìƒì„±
                        # cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                        # pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                        # draw = ImageDraw.Draw(pil_img)
                        # #draw.text((x1, y1 - 80), f"State: {current_state}", font=font, fill=(255, 255, 0))
                        # draw.text((x1, y1 - 40), f"Count: {crunch_count} | Correct Ratio: {correct_ratio:.2f} | {prediction_text}", font=font, fill=(255, 0, 0))
                        # frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

                        # mp_drawing.draw_landmarks(person_roi, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                        
                        # íšŸìˆ˜ í‘œì‹œ
                        count_placeholder.info(f"í¬ëŸ°ì¹˜ íšŸìˆ˜ : {crunch_count}/{target_reps}    í¬ëŸ°ì¹˜ ì˜¤ìì„¸ íšŸìˆ˜ : {wrong_crunch_count}     ì„¸íŠ¸ : {completed_sets}/{target_sets}")
                        # count_placeholder.info(f"í¬ëŸ°ì¹˜ íšŸìˆ˜ : {crunch_count}/{target_reps}   ì„¸íŠ¸ : {completed_sets}/{target_sets}")

                    except IndexError:
                        print("IndexError: ëœë“œë§ˆí¬ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜")

        # íšŒì „ëœ í”„ë ˆì„ì„ í‘œì‹œ
        frame_placeholder.image(frame, channels="BGR")

        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()

    results_dict["ì •ìì„¸ íšŸìˆ˜"] = completed_sets * target_reps
    results_dict['ì˜¤ìì„¸ íšŸìˆ˜'] = wrong_crunch_count
    
    total_feedback = results_dict['ë¬´ë¦ì´ ë°œëì„ ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.'] + results_dict['ëª¸ì˜ ê· í˜•ì„ ìœ ì§€í•˜ì„¸ìš”. ìƒì²´ê°€ ë„ˆë¬´ ê¸°ìš¸ì–´ì¡ŒìŠµë‹ˆë‹¤.'] + results_dict['ì—‰ë©ì´ì™€ í—ˆë¦¬ë¥¼ ì¼ì§ì„ ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”.']
    results_dict['ë¬´ë¦ì´ ë°œëì„ ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.'] = round(results_dict['ë¬´ë¦ì´ ë°œëì„ ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.'] / total_feedback, 5)
    results_dict['ëª¸ì˜ ê· í˜•ì„ ìœ ì§€í•˜ì„¸ìš”. ìƒì²´ê°€ ë„ˆë¬´ ê¸°ìš¸ì–´ì¡ŒìŠµë‹ˆë‹¤.'] = round(results_dict['ëª¸ì˜ ê· í˜•ì„ ìœ ì§€í•˜ì„¸ìš”. ìƒì²´ê°€ ë„ˆë¬´ ê¸°ìš¸ì–´ì¡ŒìŠµë‹ˆë‹¤.'] / total_feedback , 5)
    results_dict['ì—‰ë©ì´ì™€ í—ˆë¦¬ë¥¼ ì¼ì§ì„ ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”.'] = round(results_dict['ì—‰ë©ì´ì™€ í—ˆë¦¬ë¥¼ ì¼ì§ì„ ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”.'] / total_feedback, 5)
    

    return results_dict

