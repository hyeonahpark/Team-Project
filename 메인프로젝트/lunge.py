# pushup.py
import cv2
import joblib
import math
import numpy as np
from PIL import ImageFont, Image, ImageDraw
import mediapipe as mp
import time
from ultralytics import YOLO

label = ['ì •ìì„¸', 'ì˜¤ìì„¸']
model = YOLO('yolov5/yolo11n.pt')
# pushup_model = joblib.load('C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/_data/ìš´ë™ë³„ ëª¨ë¸/lunge.pkl')
pushup_model = joblib.load('C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/_data/ëŸ°ì§€_ìœ íŠ­/ëª¨ë¸_ì „ì´_3/cat_model_updated.pkl')
font_path = "C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/_data/ê°•ì›êµìœ¡íŠ¼íŠ¼.ttf"
font = ImageFont.truetype(font_path, 20)

mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose

def lunge_info(st):
    st.markdown("<h1 style='text-align: center;'>ğŸ‹ï¸â€â™‚ï¸ AI í™ˆíŠ¸ë ˆì´ë„ˆ</h1>", unsafe_allow_html=True)

    with st.container():
        st.markdown("""
                <div style="
                    background-color: #fff; 
                    padding: 30px; 
                    border-radius: 15px; 
                    border: 1px solid #ddd; 
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); 
                    max-width: 600px; 
                    margin: auto;
                    font-family: 'Roboto', Arial, sans-serif;
                ">
                    <div>
                        <h2 style="font-size: 20px; color: #333; margin: 0; text-align: center;">ëŸ°ì§€</h3>
                        <h3 style="font-size: 18px; color: #333; margin: 0;">1. ì¹´ë©”ë¼ ì„¤ì • ì•ˆë‚´</h3>
                        <ul style="font-size: 14px; color: #555; line-height: 1.8; padding-left: 20px; margin-top: 10px;">
                            <li>íœ´ëŒ€í°ì„ ë°”ë‹¥ì— ì„¸ì›Œë‘ì‹œê³ , <b>ì •ë©´ìœ¼ë¡œ ì „ì‹ </b>ì´ í™”ë©´ì— ì˜ ë‚˜ì˜¤ë„ë¡ ì¹´ë©”ë¼ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.</li>
                            <li>ì£¼ë³€ í™˜ê²½ì´ ë°ê³ , ì´¬ì˜ì— ë°©í•´ë˜ì§€ ì•Šë„ë¡ ì •ë¦¬í•´ì£¼ì„¸ìš”.</li>
                        </ul>
                    </div>
                    <div style="
                        border-top: 1px solid #eee; 
                        padding-top: 20px; 
                        margin-top: 20px;
                    ">
                        <h3 style="font-size: 18px; color: #333; margin: 0;">2. ìš´ë™ ì‹œì‘</h3>
                        <ul style="font-size: 14px; color: #555; line-height: 1.8; padding-left: 20px; margin-top: 10px;">
                            <li>ì¤€ë¹„ê°€ ì™„ë£Œë˜ì…¨ë‹¤ë©´, 'ë‹¤ìŒ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!</li>
                            <li>ìš´ë™ì´ ë°”ë¡œ ì‹œì‘ë©ë‹ˆë‹¤!</li>
                        </ul>
                    </div>
                </div>
                """, unsafe_allow_html=True)
        st.image("C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/_data/ì‚¬ì´ë“œëŸ°ì§€.png", use_container_width=True)
    
        if st.button("ë‹¤ìŒ"):
            st.session_state.current_exercise_state = "camera"
            st.rerun()

def calculate_distance(point1, point2):
    return math.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2 + (point1.z - point2.z)**2)


def calculate_angle(point_a, point_b, point_c):
    ab = (point_b.x - point_a.x, point_b.y - point_a.y, point_b.z - point_a.z)
    bc = (point_c.x - point_b.x, point_c.y - point_b.y, point_c.z - point_b.z)
    dot_product = sum(a * b for a, b in zip(ab, bc))
    magnitude_ab = math.sqrt(sum(a**2 for a in ab))
    magnitude_bc = math.sqrt(sum(b**2 for b in bc)) 
    if magnitude_ab == 0 or magnitude_bc == 0:
        return 0.0
    return math.degrees(math.acos(dot_product / (magnitude_ab * magnitude_bc)))


def flip_landmarks(landmarks):
    flipped = [None] * len(landmarks)
    swap_indices = {0: 0, 1: 4, 2: 5, 3: 6, 4: 1, 5: 2, 6: 3, 7: 8, 8: 7, 9: 10, 10: 9, 11: 12, 12: 11, 13: 14,
                   14: 13, 15: 16, 16: 15, 17: 18, 18: 17, 19: 20, 20: 19, 21: 22, 22: 21, 23: 24, 24: 23, 25: 26,
                   26: 25, 27: 28, 28: 27, 29: 30, 30: 29, 31: 32, 32: 31}
    for idx, lm in enumerate(landmarks):
        # ì¢Œìš° ëŒ€ì¹­ ìœ„ì¹˜ ê²°ì •
        new_idx = swap_indices.get(idx, idx)  # ì¢Œìš°ê°€ ë°”ë€ŒëŠ” ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
        flipped[new_idx] = type(lm)(
            x=1.0 - lm.x,  # X ì¢Œí‘œ ë°˜ì „
            y=lm.y,  # Y, Z ì¢Œí‘œëŠ” ê·¸ëŒ€ë¡œ
            z=lm.z,
            visibility=lm.visibility
        )
    return flipped

def run_lunge_session(st, YOLO, info):
    total_history = []  # ì „ì²´ í”„ë ˆì„ì˜ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
    correct_threshold = 0.7  # ì •ìì„¸ ë¹„ìœ¨ ê¸°ì¤€ (70%)
    frame_skip = 4
    frame_count = 0
    lunge_count = 0  # í‘¸ì‹œì—… ê°œìˆ˜
    wrong_count = 0
    state = "ì—…"

    # ì´ì „ í”„ë ˆì„ ë¬´ë¦ ì¢Œí‘œ ì´ˆê¸°í™”
    previous_left_hip_y = None
    previous_right_hip_y = None
    
    # ì„¸íŠ¸ ë° íšŸìˆ˜ ì„¤ì •
    target_reps = info["íšŸìˆ˜"]  # ëª©í‘œ íšŸìˆ˜
    target_sets = info["ì„¸íŠ¸"]  # ëª©í‘œ ì„¸íŠ¸
    completed_sets = 0  # ì™„ë£Œëœ ì„¸íŠ¸ ìˆ˜

    ###################### ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™” ######################
    results_dict = {
        "ì •ìì„¸ íšŸìˆ˜": 0,
        "ì˜¤ìì„¸ íšŸìˆ˜": 0,
        "ë¬´ë¦ì´ ë„ˆë¬´ ì•ìœ¼ë¡œ ë‚˜ê°”ì–´ìš”. ì¡°ê¸ˆë§Œ ë’¤ë¡œ": 0,
        "ì•ë¬´ë¦ì„ 90ë„ë¡œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.": 0,
        "ë’·ë¬´ë¦ ë„ˆë¬´ ë‚´ë ¤ê°€ì§€ ë§ˆì„¸ìš”.": 0,
        "í—ˆë¦¬ ì­‰ í´ê³  ìƒì²´ë¥¼ ë°”ë¥´ê²Œ í•´ì£¼ì„¸ìš”.": 0
    }
    ##########################################################################

    # MediaPipe Pose ì´ˆê¸°í™”
    mp_drawing = mp.solutions.drawing_utils
    mp_pose = mp.solutions.pose

    # ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ ì´ˆê¸°í™”
    st.markdown("<h1 style='text-align: center;'>ëŸ°ì§€</h1>", unsafe_allow_html=True)

    # ìŠ¤íŠ¸ë¦¬ë° ë¹„ë””ì˜¤ í”¼ë“œ ì„¤ì •
    video_url = "C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/ì˜ìƒ/ëŸ°ì§€/í˜„ì•„6.mp4"
    ip_webcam_url = "http://192.168.0.98:8080/video"    

    # ì±„íŒ… ë©”ì‹œì§€ ì°½
    frame_placeholder = st.empty()
    chat_placeholder = st.empty()
    count_placeholder = st.empty()
    set_placeholder = st.empty()  # ì„¸íŠ¸ í‘œì‹œìš©

    # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    cap = cv2.VideoCapture(video_url)  # ë™ì˜ìƒ ì…ë ¥
    # cap = cv2.VideoCapture(0)       # ì›¹ìº 
    # cap = cv2.VideoCapture(ip_webcam_url) # í° ì¹´ë©”ë¼
    cap.set(cv2.CAP_PROP_FPS, 15)

    if "feedback_display_start_time" not in st.session_state:
        st.session_state.feedback_display_start_time = None 

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        if frame_count % frame_skip != 0:  # í”„ë ˆì„ ê±´ë„ˆë›°ê¸°
            continue
        
        # frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
        
        # YOLO ëª¨ë¸ë¡œ ì‚¬ëŒ ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
        results = model(frame)
        best_box = None
        best_confidence = 0.0

        for result in results:
            for box in result.boxes:
                class_id = box.cls[0]
                confidence = box.conf[0]
                if int(class_id) == 0 and confidence > best_confidence:
                    best_box = box
                    best_confidence = confidence

        if best_box is not None:
            x1, y1, x2, y2 = map(int, best_box.xyxy[0])
            person_roi = frame[y1:y2, x1:x2]

            with mp_pose.Pose(static_image_mode=False, model_complexity=1) as pose:
                results_pose = pose.process(cv2.cvtColor(person_roi, cv2.COLOR_BGR2RGB))
                landmarks_data = []

                if results_pose.pose_landmarks:
                    try:
                        # Mediapipe ëœë“œë§ˆí¬ ì¶”ì¶œ
                        landmarks = results_pose.pose_landmarks.landmark

                        # ì´í›„ landmarks ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ëª¨ë¸ì— ë„£ì„ ë°ì´í„° êµ¬ì„±
                        landmarks_data = []
                        # indices_to_include = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]

                        indices_to_include = [11, 12, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]

                        for i in indices_to_include:
                            landmark = landmarks[i]
                            landmarks_data.extend([landmark.x, landmark.y, landmark.z])

                        # í—ˆë¦¬ ì¢Œí‘œ ê³„ì‚°
                        waist_x = (landmarks[23].x + landmarks[24].x) / 2
                        waist_y = (landmarks[23].y + landmarks[24].y) / 2
                        waist_z = (landmarks[23].z + landmarks[24].z) / 2
                        landmarks_data.extend([waist_x, waist_y, waist_z])

                        # ê±°ë¦¬ ê³„ì‚°
                        foot_distance = calculate_distance(landmarks[29], landmarks[30])  # ì¢Œìš° ë°œ ê°„ ê±°ë¦¬
                        left_knee_to_foot_distance = calculate_distance(landmarks[25], landmarks[29])  # ì™¼ìª½ ë¬´ë¦-ë°œ ê±°ë¦¬
                        right_knee_to_foot_distance = calculate_distance(landmarks[26], landmarks[30])  # ì˜¤ë¥¸ìª½ ë¬´ë¦-ë°œ ê±°ë¦¬

                        # ê°ë„ ê³„ì‚°
                        left_knee_angle = calculate_angle(landmarks[23], landmarks[25], landmarks[27])
                        right_knee_angle = calculate_angle(landmarks[24], landmarks[26], landmarks[28])
                        left_hip_angle = calculate_angle(landmarks[11], landmarks[23], landmarks[25])
                        right_hip_angle = calculate_angle(landmarks[12], landmarks[24], landmarks[26])
                        torso_angle = calculate_angle(landmarks[11], landmarks[23], landmarks[29])  # ìƒì²´ì™€ ë°”ë‹¥ ê°„ ê°ë„

                        landmarks_data.extend([
                            left_knee_angle, right_knee_angle,
                            left_hip_angle, right_hip_angle,
                            foot_distance, left_knee_to_foot_distance,
                            right_knee_to_foot_distance, torso_angle
                        ])
                        
                        prediction = pushup_model.predict([landmarks_data])
                        prediction_text = label[int(prediction[0])]

                        # ì „ì²´ ê¸°ë¡ì— ì¶”ê°€
                        total_history.append(prediction_text == "ì •ìì„¸")

                        # ì •ìì„¸ ë¹„ìœ¨ ê³„ì‚°
                        correct_ratio = sum(total_history) / len(total_history)
                        print(f"Correct Ratio: {correct_ratio:.2f}")

                        left_hip_y = landmarks[23].y
                        right_hip_y = landmarks[24].y   
                        
                        print(f"left_hip_y : {left_hip_y}, right_hip_y : {right_hip_y}")
                        print(f"previous_left_hip_y: {previous_left_hip_y}, previous_right_hip_y: {previous_right_hip_y}")
                        print(f"lunge_count: {lunge_count}")
                        
                        # # ì²« í”„ë ˆì„ì—ì„œëŠ” ì´ˆê¸°í™”ë§Œ ìˆ˜í–‰
                        # if previous_left_hip_y is None or previous_right_hip_y is None:
                        #     previous_left_hip_y = left_hip_y
                        #     previous_right_hip_y = right_hip_y
                        #     continue

                        avg_knee_angle = min(left_knee_angle, right_knee_angle)
                        
                        if avg_knee_angle < 90:
                            if state == 'ë‹¤ìš´': 
                                state = 'ì—…'
                                if correct_ratio >= correct_threshold:
                                    lunge_count += 1
                                    total_history = []
                                    if lunge_count == target_reps:
                                        completed_sets += 1
                                        lunge_count = 0
                                        
                                        if completed_sets == target_sets:
                                            st.success("ëª¨ë“  ì„¸íŠ¸ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!")
                                            cap.release()
                                            cv2.destroyAllWindows()
                                            results_dict["ì •ìì„¸ íšŸìˆ˜"] = completed_sets * target_reps
                                            return results_dict          
                                elif correct_ratio <= 0.5:
                                    wrong_count += 1
                                    total_history = []
                        elif avg_knee_angle >= 90 and avg_knee_angle<= 100:
                            state = 'ë‹¤ìš´'
                            
                        print('ê°ë„ : ', avg_knee_angle)

                        # "ì˜¤ìì„¸"ì¸ ê²½ìš° í”¼ë“œë°± ìƒì„± ë° ì¶œë ¥
                        if prediction_text == "ì˜¤ìì„¸" :
                            feedback_messages = []
                            
                            # ì•ë¬´ë¦ ìœ„ì¹˜ í”¼ë“œë°±
                            if landmarks[26].x > landmarks[32].x:  # ì•ë¬´ë¦ì´ ì•ë°œë³´ë‹¤ ì•ì— ìˆì„ë•Œ
                                results_dict["ë¬´ë¦ì´ ë„ˆë¬´ ì•ìœ¼ë¡œ ë‚˜ê°”ì–´ìš”. ì¡°ê¸ˆë§Œ ë’¤ë¡œ"] += 1
                                feedback_messages.append("ë¬´ë¦ì´ ë„ˆë¬´ ì•ìœ¼ë¡œ ë‚˜ê°”ì–´ìš”. ì¡°ê¸ˆë§Œ ë’¤ë¡œ")

                            # ì•ë¬´ë¦ ê°ë„ í”¼ë“œë°±
                            if right_knee_angle > 95:  # ì•ë¬´ë¦ì´ 90ë„ ë³´ë‹¤ í´ë•Œ
                                results_dict["ì•ë¬´ë¦ì„ 90ë„ë¡œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”."] += 1
                                feedback_messages.append("ì•ë¬´ë¦ì„ 90ë„ë¡œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.")

                            # ë’·ë¬´ë¦ í”¼ë“œë°±
                            if left_knee_angle < 95:  # ë’·ë¬´ë¦ì´ 90ë„ì— ê°€ê¹Œìš¸ë•Œ
                                results_dict["ë’·ë¬´ë¦ ë„ˆë¬´ ë‚´ë ¤ê°€ì§€ ë§ˆì„¸ìš”."] += 1
                                feedback_messages.append("ë’·ë¬´ë¦ ë„ˆë¬´ ë‚´ë ¤ê°€ì§€ ë§ˆì„¸ìš”.")

                            # ìƒì²´ í”¼ë“œë°±
                            # if abs(landmark[0] - waist_x) > 0.1:  # ìƒì²´ê°€ ë˜‘ë°”ë¡œ ì„œ ìˆì§€ ì•Šì„ ë•Œ
                            if abs(torso_angle) > 0.1:  # ìƒì²´ê°€ ë˜‘ë°”ë¡œ ì„œ ìˆì§€ ì•Šì„ ë•Œ 
                                results_dict["í—ˆë¦¬ ì­‰ í´ê³  ìƒì²´ë¥¼ ë°”ë¥´ê²Œ í•´ì£¼ì„¸ìš”."] += 1
                                feedback_messages.append("í—ˆë¦¬ ì­‰ í´ê³  ìƒì²´ë¥¼ ë°”ë¥´ê²Œ í•´ì£¼ì„¸ìš”.")
                            
                            # í”¼ë“œë°± ì¶œë ¥
                            if feedback_messages:
                                feedback_text = "<br>".join(feedback_messages)
                                chat_placeholder.markdown(feedback_text, unsafe_allow_html=True)
                                st.session_state.feedback_display_start_time = time.time()  # í”¼ë“œë°± í‘œì‹œ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                        else:
                            # "ì˜¤ìì„¸"ê°€ ì•„ë‹ ê²½ìš° í”¼ë“œë°± ë‚´ìš©ì„ 5ì´ˆ í›„ì— ì§€ì›ë‹ˆë‹¤.
                            if st.session_state.feedback_display_start_time and time.time() - st.session_state.feedback_display_start_time > 5:
                                chat_placeholder.markdown("", unsafe_allow_html=True)
                                st.session_state.feedback_display_start_time = None  # í‘œì‹œ ì‹œê°„ ì´ˆê¸°í™”
                        
                        #  # ì¶œë ¥ í…ìŠ¤íŠ¸ ìƒì„±
                        # cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                        # pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                        # draw = ImageDraw.Draw(pil_img)
                        # #draw.text((x1, y1 - 80), f"State: {current_state}", font=font, fill=(255, 255, 0))
                        # draw.text((x1, y1 - 40), f"Count: {side_lunge_count} | Correct Ratio: {correct_ratio:.2f} | {prediction_text}", font=font, fill=(255, 0, 0))
                        # frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

                        # mp_drawing.draw_landmarks(person_roi, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                        
                        # íšŸìˆ˜ í‘œì‹œ
                        count_placeholder.info(f"ëŸ°ì§€ íšŸìˆ˜ : {lunge_count}/{target_reps}     ëŸ°ì§€ ì˜¤ìì„¸ íšŸìˆ˜ : {wrong_count}    ì„¸íŠ¸ : {completed_sets}/{target_sets}")
                        # count_placeholder.info(f"ëŸ°ì§€ íšŸìˆ˜ : {lunge_count}/{target_reps}   ì„¸íŠ¸ : {completed_sets}/{target_sets}")

                    except IndexError:
                        print("IndexError: ëœë“œë§ˆí¬ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜")

        frame_placeholder.image(frame, channels="BGR", use_container_width=True)

        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()

    results_dict["ì •ìì„¸ íšŸìˆ˜"] = completed_sets * target_reps
    results_dict['ì˜¤ìì„¸ íšŸìˆ˜'] = wrong_count
    
    total_feedback = results_dict['ë¬´ë¦ì´ ë„ˆë¬´ ì•ìœ¼ë¡œ ë‚˜ê°”ì–´ìš”. ì¡°ê¸ˆë§Œ ë’¤ë¡œ'] + results_dict['ì•ë¬´ë¦ì„ 90ë„ë¡œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.'] + results_dict['ë’·ë¬´ë¦ ë„ˆë¬´ ë‚´ë ¤ê°€ì§€ ë§ˆì„¸ìš”.'] + results_dict['í—ˆë¦¬ ì­‰ í´ê³  ìƒì²´ë¥¼ ë°”ë¥´ê²Œ í•´ì£¼ì„¸ìš”.']
    results_dict['ë¬´ë¦ì´ ë„ˆë¬´ ì•ìœ¼ë¡œ ë‚˜ê°”ì–´ìš”. ì¡°ê¸ˆë§Œ ë’¤ë¡œ'] = round(results_dict['ë¬´ë¦ì´ ë„ˆë¬´ ì•ìœ¼ë¡œ ë‚˜ê°”ì–´ìš”. ì¡°ê¸ˆë§Œ ë’¤ë¡œ'] / total_feedback, 5)
    results_dict['ì•ë¬´ë¦ì„ 90ë„ë¡œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.'] = round(results_dict['ì•ë¬´ë¦ì„ 90ë„ë¡œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.'] / total_feedback , 5)
    results_dict['ë’·ë¬´ë¦ ë„ˆë¬´ ë‚´ë ¤ê°€ì§€ ë§ˆì„¸ìš”.'] = round(results_dict['ë’·ë¬´ë¦ ë„ˆë¬´ ë‚´ë ¤ê°€ì§€ ë§ˆì„¸ìš”.'] / total_feedback, 5)
    results_dict['í—ˆë¦¬ ì­‰ í´ê³  ìƒì²´ë¥¼ ë°”ë¥´ê²Œ í•´ì£¼ì„¸ìš”.'] = round(results_dict['í—ˆë¦¬ ì­‰ í´ê³  ìƒì²´ë¥¼ ë°”ë¥´ê²Œ í•´ì£¼ì„¸ìš”.'] / total_feedback, 5)
    

    return results_dict