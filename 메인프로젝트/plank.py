# pushup.py
import cv2
import joblib
import math
import numpy as np
from PIL import ImageFont, Image, ImageDraw
import mediapipe as mp
import time
from ultralytics import YOLO

label = ['ì •ìì„¸', 'ì˜¤ìì„¸']
model = YOLO('yolov5/yolo11n.pt')
plank_model = joblib.load('C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/_data/ìš´ë™ë³„ ëª¨ë¸/plank.pkl')
font_path = "C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/_data/ê°•ì›êµìœ¡íŠ¼íŠ¼.ttf"
font = ImageFont.truetype(font_path, 20)

mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose

def plank_info(st):
    st.markdown("<h1 style='text-align: center;'>ğŸ‹ï¸â€â™‚ï¸ AI í™ˆíŠ¸ë ˆì´ë„ˆ</h1>", unsafe_allow_html=True)

    with st.container():
        st.markdown("""
                <div style="
                    background-color: #fff; 
                    padding: 30px; 
                    border-radius: 15px; 
                    border: 1px solid #ddd; 
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); 
                    max-width: 600px; 
                    margin: auto;
                    font-family: 'Roboto', Arial, sans-serif;
                ">
                    <div>
                        <h2 style="font-size: 20px; color: #333; margin: 0; text-align: center;">í”Œë­í¬</h3>
                        <h3 style="font-size: 18px; color: #333; margin: 0;">1. ì¹´ë©”ë¼ ì„¤ì • ì•ˆë‚´</h3>
                        <ul style="font-size: 14px; color: #555; line-height: 1.8; padding-left: 20px; margin-top: 10px;">
                            <li>íœ´ëŒ€í°ì„ ë°”ë‹¥ì— ì„¸ì›Œë‘ì‹œê³ , <b>ì¢Œì¸¡</b> ë˜ëŠ” <b>ìš°ì¸¡ ì „ì‹ </b>ì´ í™”ë©´ì— ì˜ ë‚˜ì˜¤ë„ë¡ ì¹´ë©”ë¼ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.</li>
                            <li>ì£¼ë³€ í™˜ê²½ì´ ë°ê³ , ì´¬ì˜ì— ë°©í•´ë˜ì§€ ì•Šë„ë¡ ì •ë¦¬í•´ì£¼ì„¸ìš”.</li>
                        </ul>
                    </div>
                    <div style="
                        border-top: 1px solid #eee; 
                        padding-top: 20px; 
                        margin-top: 20px;
                    ">
                        <h3 style="font-size: 18px; color: #333; margin: 0;">2. ìš´ë™ ì‹œì‘</h3>
                        <ul style="font-size: 14px; color: #555; line-height: 1.8; padding-left: 20px; margin-top: 10px;">
                            <li>ì¤€ë¹„ê°€ ì™„ë£Œë˜ì…¨ë‹¤ë©´, 'ë‹¤ìŒ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!</li>
                            <li>ìš´ë™ì´ ë°”ë¡œ ì‹œì‘ë©ë‹ˆë‹¤!</li>
                        </ul>
                    </div>
                </div>
                """, unsafe_allow_html=True)
        st.image("C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/_data/í”Œë­í¬.png", use_container_width=True)
    
        if st.button("ë‹¤ìŒ"):
            st.session_state.current_exercise_state = "camera"
            st.rerun()

def calculate_distance(point1, point2):
    return math.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2 + (point1.z - point2.z)**2)


def calculate_angle(point_a, point_b, point_c):
    ab = (point_b.x - point_a.x, point_b.y - point_a.y, point_b.z - point_a.z)
    bc = (point_c.x - point_b.x, point_c.y - point_b.y, point_c.z - point_b.z)
    dot_product = sum(a * b for a, b in zip(ab, bc))
    magnitude_ab = math.sqrt(sum(a**2 for a in ab))
    magnitude_bc = math.sqrt(sum(b**2 for b in bc)) 
    if magnitude_ab == 0 or magnitude_bc == 0:
        return 0.0
    return math.degrees(math.acos(dot_product / (magnitude_ab * magnitude_bc)))


def flip_landmarks(landmarks):
    flipped = [None] * len(landmarks)
    swap_indices = {
        0: 0, 1: 4, 2: 5, 3: 6, 4: 1, 5: 2, 6: 3, 7: 8, 8: 7,
        9: 10, 10: 9, 11: 12, 12: 11, 13: 14, 14: 13, 15: 16, 16: 15,
        17: 18, 18: 17, 19: 20, 20: 19, 21: 22, 22: 21, 23: 24, 24: 23,
        25: 26, 26: 25, 27: 28, 28: 27, 29: 30, 30: 29, 31: 32, 32: 31,
    }
    for idx, lm in enumerate(landmarks):
        new_idx = swap_indices.get(idx, idx)
        flipped[new_idx] = type(lm)(
            x=1.0 - lm.x,
            y=lm.y,
            z=lm.z,
            visibility=lm.visibility
        )
    return flipped

##################### í”Œë­í¬ë¡œ ë³€ê²½ í•„ìš” #####################
def run_plank_session(st, YOLO, info):
    # ì´ˆê¸° ë³€ìˆ˜ ì„¤ì •
    plank_time_correct = 0  # ì •ìì„¸ ëˆ„ì  ì‹œê°„
    plank_time_wrong = 0  # ì˜¤ìì„¸ ëˆ„ì  ì‹œê°„
    total_history = []  # ì „ì²´ í”„ë ˆì„ì˜ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
    correct_threshold = 0.5  # ì •ìì„¸ ë¹„ìœ¨ ê¸°ì¤€ (70%)
    current_state = "ëŒ€ê¸°"  # ì´ˆê¸° ìƒíƒœëŠ” "ëŒ€ê¸°"
    
    # ì„¸íŠ¸ ë° ëª©í‘œ ì‹œê°„ ì„¤ì •
    target_time = info["ì´ˆ"]  # ëª©í‘œ ì‹œê°„ (ì´ˆ ë‹¨ìœ„)
    target_sets = info["ì„¸íŠ¸"]  # ëª©í‘œ ì„¸íŠ¸
    completed_sets = 0  # ì™„ë£Œëœ ì„¸íŠ¸ ìˆ˜

    frame_skip = 4  # 1 í”„ë ˆì„ ê±´ë„ˆë›°ê¸°
    frame_count = 0  # í”„ë ˆì„ ì¹´ìš´í„° ì´ˆê¸°í™”
    start_time = None  # ì •ìì„¸ ì‹œì‘ ì‹œê°„
    is_holding = False  # ì •ìì„¸ ìœ ì§€ ì—¬ë¶€

    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    results_dict = {
        "ì •ìì„¸ ì‹œê°„": 0,
        "ì˜¤ìì„¸ ì‹œê°„": 0,
        "ì–´ê¹¨ì™€ ì†ì˜ ìœ„ì¹˜ë¥¼ ì¼ì¹˜í•˜ê²Œ í•´ì£¼ì„¸ìš”.": 0,
        "ëª©ê³¼ í—ˆë¦¬, ì—‰ë©ì´, ë‹¤ë¦¬ê°€ ì¼ì§ì„ ì´ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”.": 0,
        "ì—‰ë©ì´ë¥¼ ì–‘ìª½ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ì„¸ìš”.": 0,
        "ê³ ê°œê°€ ì •ë©´ì„ í–¥í•˜ê²Œ í•´ì£¼ì„¸ìš”.": 0,
    }

    # MediaPipe Pose ì´ˆê¸°í™”
    mp_drawing = mp.solutions.drawing_utils
    mp_pose = mp.solutions.pose

    # ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ ì´ˆê¸°í™”
    st.markdown("<h1 style='text-align: center;'>í”Œë­í¬</h1>", unsafe_allow_html=True)

    # ìŠ¤íŠ¸ë¦¬ë° ë¹„ë””ì˜¤ í”¼ë“œ ì„¤ì •
    video_url = "C:/ai5/ë³¸í”„ë¡œì íŠ¸/ë©”ì¸/ì˜ìƒ/í”Œë­í¬/ì‚¬ì˜1.mp4"
    ip_webcam_url = "http://192.168.0.98:8080/video"    

    # ì±„íŒ… ë©”ì‹œì§€ ì°½
    frame_placeholder = st.empty()
    chat_placeholder = st.empty()
    time_placeholder = st.empty()
    set_placeholder = st.empty()  # ì„¸íŠ¸ í‘œì‹œìš©

    # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    cap = cv2.VideoCapture(video_url) # ë™ì˜ìƒ
    # cap = cv2.VideoCapture(ip_webcam_url) # í° ì¹´ë©”ë¼
    # cap = cv2.VideoCapture(0)       # ì›¹ìº 
    
    cap.set(cv2.CAP_PROP_FPS, 15)    
    
    if "feedback_display_start_time" not in st.session_state:
        st.session_state.feedback_display_start_time = None 

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        if frame_count % frame_skip != 0:  # í”„ë ˆì„ ê±´ë„ˆë›°ê¸°
            continue
        
        # í”„ë ˆì„ íšŒì „
        # frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)


        # YOLO ëª¨ë¸ë¡œ ì‚¬ëŒ ë°”ìš´ë”© ë°•ìŠ¤ ìƒì„±
        results = model(frame)
        best_box = None
        best_confidence = 0.0

        for result in results:
            for box in result.boxes:
                class_id = box.cls[0]
                confidence = box.conf[0]
                if int(class_id) == 0 and confidence > best_confidence:
                    best_box = box
                    best_confidence = confidence

        if best_box is not None:
            x1, y1, x2, y2 = map(int, best_box.xyxy[0])
            person_roi = frame[y1:y2, x1:x2]

            with mp_pose.Pose(static_image_mode=False, model_complexity=2) as pose:
                results_pose = pose.process(cv2.cvtColor(person_roi, cv2.COLOR_BGR2RGB))
                if results_pose.pose_landmarks:
                    try:
                        landmarks = results_pose.pose_landmarks.landmark

                        # ì¢Œìš° ë°˜ì „ ê°ì§€
                        nose_x = landmarks[0].x
                        hip_mid_x = (landmarks[23].x + landmarks[24].x) / 2
                        is_right_facing = nose_x > hip_mid_x
                        
                        if is_right_facing:
                            landmarks = flip_landmarks(landmarks)
                        else:
                            landmarks = landmarks
                            
                        # ëœë“œë§ˆí¬ ë°ì´í„° ìƒì„±
                        landmarks_data = []
                        for idx in [11, 12, 23, 24, 25, 26, 27, 28]:
                            print(f"Landmark {idx}: X={landmarks[idx].x}, Y={landmarks[idx].y}, Z={landmarks[idx].z}")
                            landmarks_data.extend([landmarks[idx].x, landmarks[idx].y, landmarks[idx].z])

                        left_hip_angle = calculate_angle(landmarks[11], landmarks[23], landmarks[25])
                        right_hip_angle = calculate_angle(landmarks[12], landmarks[24], landmarks[26])
                        left_knee_angle = calculate_angle(landmarks[23], landmarks[25], landmarks[27])
                        right_knee_angle = calculate_angle(landmarks[24], landmarks[26], landmarks[28])
                        shoulder_balance = abs(landmarks[11].y - landmarks[12].y)
                        hip_balance = abs(landmarks[23].y - landmarks[24].y)

                        landmarks_data.extend([
                            left_hip_angle, right_hip_angle,
                            left_knee_angle, right_knee_angle,
                            shoulder_balance, hip_balance
                        ])

                        prediction = plank_model.predict([landmarks_data])
                        prediction_text = label[int(prediction[0])]

                        total_history.append(prediction_text == "ì •ìì„¸")
                        correct_ratio = sum(total_history) / len(total_history)
                        
                        # ì‹œê°„ ê³„ì‚°
                        if correct_ratio >= correct_threshold:
                            if not is_holding:
                                start_time = time.time()
                                is_holding = True
                            else:
                                elapsed_time = time.time() - start_time
                                plank_time_correct += elapsed_time
                                start_time = time.time()

                                # ì„¸íŠ¸ ì™„ë£Œ ì²˜ë¦¬
                                while plank_time_correct >= target_time:  # ì´ˆê³¼ëœ ì‹œê°„ë„ ê³„ì‚°ì— ë°˜ì˜
                                    completed_sets += 1
                                    total_history = []
                                    plank_time_correct -= target_time  # ì´ˆê³¼ëœ ì‹œê°„ì„ ë‹¤ìŒ ì„¸íŠ¸ë¡œ ë„˜ê¹€

                                    if completed_sets >= target_sets:
                                        st.success("ëª¨ë“  ì„¸íŠ¸ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!")
                                        cap.release()
                                        cv2.destroyAllWindows()
                                        return results_dict
                        else:
                            if is_holding:
                                elapsed_time = time.time() - start_time
                                plank_time_wrong += elapsed_time
                                is_holding = False
                                start_time = None

                        # "ì˜¤ìì„¸"ì¸ ê²½ìš° í”¼ë“œë°± ìƒì„± ë° ì¶œë ¥
                        if prediction_text == "ì˜¤ìì„¸":
                            feedback_messages = []

                            # ì–´ê¹¨ì™€ ì† ìœ„ì¹˜ ë¶ˆì¼ì¹˜ í”¼ë“œë°±
                            shoulder_wrist_distance_left = calculate_distance(landmarks[11], landmarks[15])
                            shoulder_wrist_distance_right = calculate_distance(landmarks[12], landmarks[16])
                            if shoulder_wrist_distance_left > 0.15 or shoulder_wrist_distance_right > 0.15:
                                results_dict["ì–´ê¹¨ì™€ ì†ì˜ ìœ„ì¹˜ë¥¼ ì¼ì¹˜í•˜ê²Œ í•´ì£¼ì„¸ìš”."] += 1
                                feedback_messages.append("ì–´ê¹¨ì™€ ì†ì˜ ìœ„ì¹˜ë¥¼ ì¼ì¹˜í•˜ê²Œ í•´ì£¼ì„¸ìš”.")

                            # ëª©-í—ˆë¦¬-ì—‰ë©ì´-ë‹¤ë¦¬ ì¼ì§ì„  í”¼ë“œë°±
                            body_alignment_angle = calculate_angle(landmarks[0], landmarks[23], landmarks[27])
                            if body_alignment_angle < 170:
                                results_dict["ëª©ê³¼ í—ˆë¦¬, ì—‰ë©ì´, ë‹¤ë¦¬ê°€ ì¼ì§ì„ ì´ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”."] += 1
                                feedback_messages.append("ëª©ê³¼ í—ˆë¦¬, ì—‰ë©ì´, ë‹¤ë¦¬ê°€ ì¼ì§ì„ ì´ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”.")

                            # ì—‰ë©ì´ ë†’ì´ ë¶ˆê· í˜• í”¼ë“œë°±
                            hip_height_difference = abs(landmarks[23].y - landmarks[24].y)
                            if hip_height_difference > 0.05:
                                results_dict["ì—‰ë©ì´ë¥¼ ì–‘ìª½ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ì„¸ìš”."] += 1
                                feedback_messages.append("ì—‰ë©ì´ë¥¼ ì–‘ìª½ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ì„¸ìš”.")

                            # ê³ ê°œ ì •ë©´ í”¼ë“œë°±
                            nose_x = landmarks[0].x
                            shoulder_center_x = (landmarks[11].x + landmarks[12].x) / 2
                            if abs(nose_x - shoulder_center_x) > 0.1:
                                results_dict["ê³ ê°œê°€ ì •ë©´ì„ í–¥í•˜ê²Œ í•´ì£¼ì„¸ìš”."] += 1
                                feedback_messages.append("ê³ ê°œê°€ ì •ë©´ì„ í–¥í•˜ê²Œ í•´ì£¼ì„¸ìš”.")

                            # í”¼ë“œë°± ì¶œë ¥
                            if feedback_messages:
                                feedback_text = "<br>".join(feedback_messages)
                                chat_placeholder.markdown(feedback_text, unsafe_allow_html=True)
                                st.session_state.feedback_display_start_time = time.time()
                        else:
                            # "ì •ìì„¸"ì¼ ê²½ìš° í”¼ë“œë°± ì œê±°
                            if st.session_state.feedback_display_start_time and time.time() - st.session_state.feedback_display_start_time > 5:
                                chat_placeholder.markdown("", unsafe_allow_html=True)
                                st.session_state.feedback_display_start_time = None
                        
                        # cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                        # pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                        # draw = ImageDraw.Draw(pil_img)
                        # draw.text(
                        #     (x1, y1 - 40),
                        #     f"Plank Time: {int(plank_time_correct)}s | Ratio: {correct_ratio:.2f} | {prediction_text}",
                        #     font=font,
                        #     fill=(255, 0, 0),
                        # )
                        # frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

                        # mp_drawing.draw_landmarks(person_roi, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)
                        
                        # í”Œë­í¬ ì‹œê°„ ë° ìƒíƒœ ì¶œë ¥
                        time_placeholder.info(f"ì •ìì„¸ ì‹œê°„: {int(plank_time_correct)}s /{int(target_time)}s    í”Œë­í¬ ì˜¤ìì„¸ ì‹œê°„ : {plank_time_wrong}s    ì„¸íŠ¸: {completed_sets}/{target_sets}")
                        # time_placeholder.info(f"ì •ìì„¸ ì‹œê°„: {int(plank_time_correct)}s /{int(target_time)}s   ì„¸íŠ¸: {completed_sets}/{target_sets}")

                    except IndexError:
                        print("IndexError: ëœë“œë§ˆí¬ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜")

        

        # íšŒì „ëœ í”„ë ˆì„ì„ í‘œì‹œ
        frame_placeholder.image(frame, channels="BGR")
        
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()

    # ê²°ê³¼ ìš”ì•½
    results_dict["ì •ìì„¸ ì‹œê°„"] = plank_time_correct
    results_dict["ì˜¤ìì„¸ ì‹œê°„"] = plank_time_wrong
    total_feedback = results_dict["ì–´ê¹¨ì™€ ì†ì˜ ìœ„ì¹˜ë¥¼ ì¼ì¹˜í•˜ê²Œ í•´ì£¼ì„¸ìš”."] + results_dict["ëª©ê³¼ í—ˆë¦¬, ì—‰ë©ì´, ë‹¤ë¦¬ê°€ ì¼ì§ì„ ì´ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”."] + results_dict["ì—‰ë©ì´ë¥¼ ì–‘ìª½ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ì„¸ìš”."] + results_dict["ê³ ê°œê°€ ì •ë©´ì„ í–¥í•˜ê²Œ í•´ì£¼ì„¸ìš”."]
    results_dict["ì–´ê¹¨ì™€ ì†ì˜ ìœ„ì¹˜ë¥¼ ì¼ì¹˜í•˜ê²Œ í•´ì£¼ì„¸ìš”."] = round(results_dict["ì–´ê¹¨ì™€ ì†ì˜ ìœ„ì¹˜ë¥¼ ì¼ì¹˜í•˜ê²Œ í•´ì£¼ì„¸ìš”."] / total_feedback, 5)
    results_dict["ëª©ê³¼ í—ˆë¦¬, ì—‰ë©ì´, ë‹¤ë¦¬ê°€ ì¼ì§ì„ ì´ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”."] = round(results_dict["ëª©ê³¼ í—ˆë¦¬, ì—‰ë©ì´, ë‹¤ë¦¬ê°€ ì¼ì§ì„ ì´ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”."] / total_feedback , 5)
    results_dict["ì—‰ë©ì´ë¥¼ ì–‘ìª½ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ì„¸ìš”."] = round(results_dict["ì—‰ë©ì´ë¥¼ ì–‘ìª½ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ì„¸ìš”."] / total_feedback, 5)
    results_dict["ê³ ê°œê°€ ì •ë©´ì„ í–¥í•˜ê²Œ í•´ì£¼ì„¸ìš”."] = round(results_dict["ê³ ê°œê°€ ì •ë©´ì„ í–¥í•˜ê²Œ í•´ì£¼ì„¸ìš”."] / total_feedback, 5)
        
    return results_dict
